{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9857c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6335bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarizer(text):\n",
    "    punctuation=string.punctuation\n",
    "    stop_words=list(stopwords.words(\"english\"))\n",
    "    token=word_tokenize(text)\n",
    "    \n",
    "    word_freq={}\n",
    "    \n",
    "    for word in token:\n",
    "        if word.lower() not in stop_words and word.lower() not in punctuation:\n",
    "            if word.lower() not in word_freq.keys():\n",
    "                word_freq[word] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    max_freq=max(word_freq.values())\n",
    "    \n",
    "    # frequency normalization \n",
    "    \n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "    \n",
    "    \n",
    "    sent_token=sent_tokenize(text)\n",
    "    \n",
    "    sent_scores={}\n",
    "    for sent in sent_token:\n",
    "        for word in sent.split(\" \"):\n",
    "            if word in word_freq.keys():\n",
    "                if sent not in sent_scores.keys():\n",
    "                    sent_scores[sent]=word_freq[word]\n",
    "                else:\n",
    "                    sent_scores[sent] += word_freq[word]\n",
    "    \n",
    "    \n",
    "    select_len=int(len(sent_token )*.30) \n",
    "\n",
    "    summery=nlargest(select_len , sent_scores ,key=sent_scores.get)\n",
    "    \n",
    "    \n",
    "    final_summary=[word for word in summery]\n",
    "    summery1=\" \".join(final_summary)\n",
    "    \n",
    "    return \"\".join(summery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3cd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter \n",
    "from tkinter import *\n",
    "import pickle\n",
    "from tkinter import messagebox\n",
    "import numpy as np\n",
    "from tkinter import ttk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1115942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "\n",
    "def Summarizer():\n",
    "    text=user_input1.get()\n",
    "    punctuation=string.punctuation\n",
    "    stop_words=list(stopwords.words(\"english\"))\n",
    "    token=word_tokenize(text)\n",
    "    \n",
    "    word_freq={}\n",
    "    \n",
    "    for word in token:\n",
    "        if word.lower() not in stop_words and word.lower() not in punctuation:\n",
    "            if word.lower() not in word_freq.keys():\n",
    "                word_freq[word] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    max_freq=max(word_freq.values())\n",
    "    \n",
    "    # frequency normalization \n",
    "    \n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word]/max_freq\n",
    "    \n",
    "    \n",
    "    sent_token=sent_tokenize(text)\n",
    "    \n",
    "    sent_scores={}\n",
    "    for sent in sent_token:\n",
    "        for word in sent.split(\" \"):\n",
    "            if word in word_freq.keys():\n",
    "                if sent not in sent_scores.keys():\n",
    "                    sent_scores[sent]=word_freq[word]\n",
    "                else:\n",
    "                    sent_scores[sent] += word_freq[word]\n",
    "    \n",
    "    \n",
    "    select_len=int(len(sent_token )*.30) \n",
    "\n",
    "    summery=nlargest(select_len , sent_scores ,key=sent_scores.get)\n",
    "    \n",
    "    \n",
    "    final_summary=[word for word in summery]\n",
    "    summery1=\" \".join(final_summary)\n",
    "    \n",
    "    final_summery=\"\".join(summery1)\n",
    "    messagebox.showinfo(\"Result\",final_summery)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root.title(\" GUI \")\n",
    "root.geometry(\"500x500\")\n",
    "root.resizable(0,0)\n",
    "\n",
    "tital=Label(root,text=\"Text_Summerization_AI\",fg=\"Black\",background=\"white\")\n",
    "tital.pack(ipady=10,pady=(5,0))\n",
    "tital.config(font=\"Verdana\")\n",
    "\n",
    "tital1=Label(root,text=\"Enter Text\",background=\"white\")\n",
    "tital1.pack(ipady=5,pady=(15,0))\n",
    "tital1.config(font=\"Verdana\")\n",
    "\n",
    "user_input1=Entry(root)\n",
    "user_input1.pack(ipady=5,pady=(10,50))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "login_but=Button(root,text=\"Get Prediction\",bg=\"white\",background=\"white\",command=Summarizer)\n",
    "login_but.pack(ipady=5,pady=(25,5))\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e411b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a878c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
